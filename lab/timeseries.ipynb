{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Timeseries Script: Process time-series for 24 hours",
   "id": "38a585bd6f0296bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import random\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "from helpers.border import find_closed_regions\n",
    "from collections import defaultdict, deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers.demand import estimate_substation_demand_average_within_planning_area, \\\n",
    "    estimate_substation_demand_average_within_planning_area_urban_check\n",
    "from helpers.position import map_cities_to_planning_areas, map_stations_to_planning_areas, get_substations_in_city_areas\n",
    "from helpers.policy import policy_helper_power_line_same_direction\n",
    "from helpers.DataLoader import DataLoader\n",
    "import networkx as nx\n"
   ],
   "id": "caa5eebb53615a1d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    \"line\": {\n",
    "        \"target_voltages\": [0, 69, 138, 240, 500]\n",
    "    }\n",
    "}"
   ],
   "id": "3c5571de9bdef17a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataloader = DataLoader()",
   "id": "17d2bac76d74c371",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_substation_total_generation(substation):\n",
    "    current_generation = 0\n",
    "    for generator in dataloader.substations_to_generators[substation]:\n",
    "            current_generation += dataloader.generators_to_capacities[generator]\n",
    "    return current_generation"
   ],
   "id": "7efa2b8539a7c6b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_subgraphs(graph_edges, remove_fixed_edges):\n",
    "    G = nx.Graph()\n",
    "\n",
    "    G.add_edges_from(graph_edges)\n",
    "\n",
    "    G.remove_edges_from(remove_fixed_edges)\n",
    "\n",
    "    subgraphs = [list(comp) for comp in nx.connected_components(G)]\n",
    "\n",
    "    return subgraphs"
   ],
   "id": "6890166c82bda371",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_subgraphs_with_io(graph_edges, remove_fixed_edges):\n",
    "    G = nx.Graph()\n",
    "    G.add_edges_from(graph_edges)\n",
    "\n",
    "    G.remove_edges_from(remove_fixed_edges)\n",
    "\n",
    "    subgraphs = [list(comp) for comp in nx.connected_components(G)]\n",
    "\n",
    "    subgraph_info = []\n",
    "\n",
    "    for subgraph in subgraphs:\n",
    "        input_nodes = set()\n",
    "        output_nodes = set()\n",
    "\n",
    "        for src, dst in remove_fixed_edges:\n",
    "            if src in subgraph and dst not in subgraph:\n",
    "                output_nodes.add(src)\n",
    "            if dst in subgraph and src not in subgraph:\n",
    "                input_nodes.add(dst)\n",
    "\n",
    "        subgraph_info.append({\n",
    "            \"subgraph\": subgraph,\n",
    "            \"input_nodes\": list(input_nodes),\n",
    "            \"output_nodes\": list(output_nodes)\n",
    "        })\n",
    "\n",
    "    return subgraph_info"
   ],
   "id": "3c4967dbb88512b8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def assign_directions(subgraph_data, original_edges, remove_fixed_edges):\n",
    "    subgraph_nodes = subgraph_data[\"subgraph\"]\n",
    "    input_nodes = set(subgraph_data[\"input_nodes\"])\n",
    "    output_nodes = set(subgraph_data[\"output_nodes\"])\n",
    "\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(subgraph_nodes)\n",
    "\n",
    "    for edge in original_edges:\n",
    "        if edge[0] in subgraph_nodes and edge[1] in subgraph_nodes and (edge[0], edge[1]) not in remove_fixed_edges and (edge[1],edge[0]) not in remove_fixed_edges:\n",
    "            G.add_edge(edge[0], edge[1])\n",
    "\n",
    "    DiG = nx.DiGraph()\n",
    "    DiG.add_nodes_from(subgraph_nodes)\n",
    "\n",
    "    visited = set()\n",
    "    queue = list(input_nodes)\n",
    "\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        visited.add(node)\n",
    "\n",
    "        for neighbor in G.neighbors(node):\n",
    "            if neighbor not in visited:\n",
    "                # Direction: node -> neighbor\n",
    "                DiG.add_edge(node, neighbor)\n",
    "                queue.append(neighbor)\n",
    "\n",
    "    return DiG"
   ],
   "id": "f2e9be9cbd2bbd83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_reachable_edges(local_edges, generators_to_substations):\n",
    "    pfg = nx.DiGraph()\n",
    "    pfg.add_edges_from(local_edges)\n",
    "\n",
    "    all_reachable_nodes = set()\n",
    "    pdf_edges = set(pfg.edges())\n",
    "\n",
    "    for generator_station in set(generators_to_substations.values()):\n",
    "        if generator_station in pfg:\n",
    "            all_reachable_nodes.update(nx.descendants(pfg, generator_station))\n",
    "\n",
    "    local_reachable_edges = {edge for edge in pdf_edges if\n",
    "                             edge[0] in all_reachable_nodes or edge[1] in all_reachable_nodes}\n",
    "\n",
    "    local_unreachable_edges = pdf_edges - local_reachable_edges\n",
    "    return pdf_edges, local_reachable_edges, local_unreachable_edges\n",
    "\n",
    "\n",
    "def find_edges_within_voltage(local_edges, target_voltages):\n",
    "    result_edges = []\n",
    "    for edge in local_edges:\n",
    "        local_lines = dataloader.undirect_station_pairs_to_line[edge]\n",
    "        local_filtered_lines = (\n",
    "            [line for line in local_lines if dataloader.lines_to_voltage[line] in target_voltages]\n",
    "        )\n",
    "\n",
    "        if local_filtered_lines:\n",
    "            result_edges.append(edge)\n",
    "\n",
    "    return result_edges"
   ],
   "id": "659ad74d0643ce4a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "activate_urban_check = True\n",
    "\n",
    "year = 2021\n",
    "\n",
    "def process_per_time_point(address):\n",
    "    dataloader.update_generator_mapping(pd.read_csv(address))\n",
    "\n",
    "    remove_fixed_edges = set()\n",
    "    for sub1, sub2 in dataloader.direct_station_pairs_to_line.keys():\n",
    "        if dataloader.substations_to_voltage[sub1] > dataloader.substations_to_voltage[sub2] and (\n",
    "                dataloader.substations_to_voltage[sub1] != 500):\n",
    "            remove_fixed_edges.add((sub1, sub2))\n",
    "        if dataloader.substations_to_voltage[sub1] < dataloader.substations_to_voltage[sub2] and (\n",
    "                dataloader.substations_to_voltage[sub2] != 500):\n",
    "            remove_fixed_edges.add((sub2, sub1))\n",
    "        if dataloader.substations_to_voltage[sub1] == dataloader.substations_to_voltage[sub2]:\n",
    "            if sub1 in dataloader.substations_to_generators and sub2 in dataloader.substations_to_generators:\n",
    "                # graph[sub1].add(sub2)\n",
    "                # graph[sub2].add(sub1)\n",
    "                pass\n",
    "            elif sub1 in dataloader.substations_to_generators and get_substation_total_generation(sub1) > 0:\n",
    "                remove_fixed_edges.add((sub1, sub2))\n",
    "            elif sub2 in dataloader.substations_to_generators and get_substation_total_generation(sub2) > 0:\n",
    "                remove_fixed_edges.add((sub2, sub1))\n",
    "            else:\n",
    "                # graph[sub1].add(sub2)\n",
    "                # graph[sub2].add(sub1)\n",
    "                pass\n",
    "\n",
    "    subgraph_info = get_subgraphs_with_io(dataloader.direct_station_pairs_to_line.keys(), remove_fixed_edges)\n",
    "\n",
    "    directed_subgraphs = []\n",
    "    for subgraph_data in subgraph_info:\n",
    "        directed_graph = assign_directions(subgraph_data, dataloader.undirect_station_pairs_to_line.keys(), remove_fixed_edges)\n",
    "        directed_subgraphs.append(directed_graph)\n",
    "\n",
    "\n",
    "    edges = set()\n",
    "    for idx, DiG in enumerate(directed_subgraphs):\n",
    "        for edge in DiG.edges:\n",
    "            edges.add(edge)\n",
    "\n",
    "    edges = edges | remove_fixed_edges\n",
    "\n",
    "    special_case_edges = []\n",
    "    for e1, e2 in dataloader.direct_station_pairs_to_line.keys():\n",
    "        if (e1, e2) not in edges and (e2, e1) not in edges:\n",
    "            special_case_edges.append((e1, e2))\n",
    "\n",
    "    for special_edge in special_case_edges:\n",
    "        edges.add(special_edge)\n",
    "\n",
    "    edges = list(set(edges))\n",
    "\n",
    "    planning_area_closed_regions = find_closed_regions(dataloader.planning_area_border_df)\n",
    "    city_closed_regions = find_closed_regions(dataloader.city_border_df)\n",
    "\n",
    "    planning_area_to_stations = map_stations_to_planning_areas(planning_area_closed_regions,\n",
    "                                                               dataloader.substations_to_coordinates)\n",
    "\n",
    "    substations_in_city_areas = get_substations_in_city_areas(city_closed_regions, dataloader.substations_to_coordinates)\n",
    "\n",
    "    planning_area_colors = sns.color_palette(\"Paired\", len(planning_area_closed_regions))\n",
    "    random.shuffle(planning_area_colors)\n",
    "\n",
    "\n",
    "    stations_outside_planning_areas = []\n",
    "\n",
    "    for name, (x, y) in dataloader.substations_to_coordinates.items():\n",
    "        station_point = Point(x, y)\n",
    "        in_any_area = False\n",
    "\n",
    "        for polygon in planning_area_closed_regions:\n",
    "            if polygon.contains(station_point):\n",
    "                in_any_area = True\n",
    "                break\n",
    "\n",
    "        if not in_any_area:\n",
    "            stations_outside_planning_areas.append(name)\n",
    "\n",
    "    # Handle exceptions: A few Alberta substations are not in the lands (not covered within any planning areas)\n",
    "    planning_area_to_stations[\"53\"].append('978S')\n",
    "    planning_area_to_stations[\"53\"].append('CRANBROOK B2S')\n",
    "    planning_area_to_stations[\"53\"].append('NATAL')\n",
    "\n",
    "    if activate_urban_check:\n",
    "        substation_demand_dict = estimate_substation_demand_average_within_planning_area_urban_check(\n",
    "            planning_area_to_stations, dataloader.planning_area_demand[year], substations_in_city_areas,\n",
    "            dataloader.get_city_population_ratio())\n",
    "    else:\n",
    "        substation_demand_dict = estimate_substation_demand_average_within_planning_area(planning_area_to_stations,\n",
    "                                                                                         dataloader.planning_area_demand[year])\n",
    "\n",
    "    # Construct directed graph\n",
    "    power_flow_graph = nx.DiGraph()\n",
    "    power_flow_graph.add_edges_from(edges)  # Add the determined directions\n",
    "\n",
    "    substation_to_load = {s: 0.0 for s in substation_demand_dict.keys()}\n",
    "\n",
    "    # Calculate the power contribution of each generator\n",
    "    for generator, station in dataloader.generators_to_substations.items():\n",
    "        if station not in power_flow_graph:\n",
    "            continue\n",
    "\n",
    "        # The supply from each generator\n",
    "        generator_capacity = float(dataloader.generators_to_capacities.get(generator, 0))\n",
    "\n",
    "        # All the reachable substations\n",
    "        reachable_substations = set(nx.descendants(power_flow_graph, station))\n",
    "        reachable_substations.add(station)\n",
    "\n",
    "        # The total demand for reachable substations\n",
    "        total_demand_index = float(sum(substation_demand_dict.get(s, 0)\n",
    "                                       for s in reachable_substations))\n",
    "        if total_demand_index == 0:\n",
    "            continue\n",
    "\n",
    "        # Allocate the generation supply to each substations\n",
    "        for substation in reachable_substations:\n",
    "            demand_index = float(substation_demand_dict.get(substation, 0))\n",
    "            load_ratio = demand_index / total_demand_index\n",
    "            substation_to_load[substation] += load_ratio * generator_capacity\n",
    "\n",
    "    return substation_to_load"
   ],
   "id": "8e44ea5315f2c94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "folder_path = \"..\\\\data\\\\timeseries\\\\local\"\n",
    "csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))"
   ],
   "id": "368fa55dc3022547",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "substation_stats = {}\n",
    "\n",
    "for file_path in csv_files:\n",
    "    substation_to_load = process_per_time_point(file_path)\n",
    "\n",
    "    for substation, load in substation_to_load.items():\n",
    "        # If the substation is new, initialize its min and max with the current load\n",
    "        if substation not in substation_stats:\n",
    "            substation_stats[substation] = {\"min\": load, \"max\": load}\n",
    "        else:\n",
    "            # Update the minimum load if the current load is lower\n",
    "            substation_stats[substation][\"min\"] = min(substation_stats[substation][\"min\"], load)\n",
    "            # Update the maximum load if the current load is higher\n",
    "            substation_stats[substation][\"max\"] = max(substation_stats[substation][\"max\"], load)\n",
    "\n",
    "print(substation_stats)\n"
   ],
   "id": "5b72a80aa0b5556b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "max_diff = None\n",
    "station_with_max_diff = None\n",
    "\n",
    "for substation, stats in substation_stats.items():\n",
    "    diff = stats[\"max\"] - stats[\"min\"]\n",
    "    if max_diff is None or diff > max_diff:\n",
    "        max_diff = diff\n",
    "        station_with_max_diff = substation\n",
    "\n",
    "print(\"Station with maximum difference:\", station_with_max_diff)\n",
    "print(\"Maximum difference:\", max_diff)\n"
   ],
   "id": "5a5083994852a1c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "target_substation = station_with_max_diff\n",
    "\n",
    "final_dictionary = {}\n",
    "# Iterate over each CSV file\n",
    "for file_path in csv_files:\n",
    "    filename = os.path.basename(file_path).replace(\".csv\", \"\")\n",
    "\n",
    "    parts = filename.split(\"_\")\n",
    "    date_str = parts[1]\n",
    "    time_str = parts[2]\n",
    "\n",
    "    # Combine date and time strings and parse them into a datetime object\n",
    "    dt = datetime.strptime(date_str + time_str, \"%Y%m%d%H%M\")\n",
    "\n",
    "    substation_to_load = process_per_time_point(file_path)\n",
    "    final_dictionary[dt] = substation_to_load[target_substation]\n"
   ],
   "id": "f498d1353ad573c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(final_dictionary)",
   "id": "c56c7ab7749dc42b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the dictionary into a list of tuples and create a DataFrame\n",
    "df = pd.DataFrame(list(final_dictionary.items()), columns=['timestamp', 'value'])\n",
    "\n",
    "# Optional: Convert the datetime objects to strings (if desired)\n",
    "df['timestamp'] = df['timestamp'].astype(str)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('..\\\\data\\\\timeseries\\\\final_dictionary.csv', index=False)\n"
   ],
   "id": "e7ff0029905fe5b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "sorted_items = sorted(final_dictionary.items())\n",
    "times, values = zip(*sorted_items)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(times, values, marker='o', markersize=4, linestyle='-')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Power Load (MW)\")\n",
    "plt.title(\"Power Load Over 24 Hour for Bus: \" + target_substation)\n",
    "\n",
    "ax = plt.gca()\n",
    "# Set the locator to show a tick every 2 hours\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(interval=2))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "\n",
    "plt.gcf().autofmt_xdate()  # Rotate date labels for clarity\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "f09776f9595f6dd6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
